# AI-Driven Mental Health Assistant

## Overview

The **AI-Driven Mental Health Assistant** is an AI-powered chatbot designed to support mental well-being by analyzing user sentiment, detecting crisis situations, and offering therapist recommendations. It runs **Llama 2 locally via Ollama** for generating responses and is currently hosted on **localhost**.

## Features

âœ… **Sentiment Analysis** â€“ Analyzes user messages to determine mood.  
ğŸš¨ **Crisis Detection** â€“ Identifies high-risk emotional states and alerts users.  
ğŸ“Š **Mood Tracking** â€“ Displays an average mood score for self-monitoring.  
ğŸŒ **Multilingual Support** â€“ Supports English & Hindi conversations.  
ğŸ” **User Authentication** â€“ Secure login system for personalized experience.  
ğŸ¤– **AI-Powered Responses** â€“ Uses **Llama 2 via Ollama** for contextual replies.  
ğŸ’¾ **Chat History** â€“ Stores previous conversations for reference.  
ğŸ¤ **Voice Input** â€“ Speech-to-text functionality for seamless interaction.  
âš¡ **Local Deployment** â€“ Ensures privacy with offline execution.  

---

## Tech Stack

### **Frontend**
- **Next.js (React)**
- **Tailwind CSS** (for UI styling)
- **Lucide Icons** (for UI elements)

### **Backend**
- **FastAPI** (Python-based web framework)
- **PostgreSQL** (Database for storing chat history)
- **Ollama** (Runs Llama 2 model locally)
- **SQLAlchemy** (ORM for database interactions)
- **SpeechRecognition API** (For voice input)

---

## Installation & Setup

### 1ï¸âƒ£ Prerequisites:
- Install **Ollama** â†’ [Download Here](https://ollama.ai/)
- Install **Node.js & npm** â†’ [Download Here](https://nodejs.org/)
- Install **Python 3.8+**
- Install **PostgreSQL** â†’ Ensure a database is set up

### 2ï¸âƒ£ Clone the Repository:
```sh
git clone https://github.com/your-repo/mental-health-assistant.git
cd mental-health-assistant```



### Backend Setup:
Create a virtual environment:

python -m venv venv
source venv/bin/activate  # On Windows use: venv\Scripts\activate

Install dependencies:

pip install -r requirements.txt

Run the backend server

python3 backend.py


### Frontend Setup:

Navigate to the frontend/ folder:

cd frontend

Install dependencies:

npm install
Start the Next.js frontend:

npm run dev

The frontend should now be running at http://localhost:3000

